{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Location</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Text</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/6/2017 05:00</td>\n",
       "      <td>Camp McGregor, NM</td>\n",
       "      <td>Light</td>\n",
       "      <td>10 minute</td>\n",
       "      <td>Light seen over mountain's east of Camp McGre...</td>\n",
       "      <td>Report appears to us to be consistent with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017 11:30</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Disk</td>\n",
       "      <td>3 second</td>\n",
       "      <td>Flying saucer descends, possibly lands in Nor...</td>\n",
       "      <td>We would like to communicate with this witne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/4/2017 21:27</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Circle</td>\n",
       "      <td>15 second</td>\n",
       "      <td>Orange round sphere.  Orange glowing sphere f...</td>\n",
       "      <td>We have amended the time above, to reflect a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/4/2017 18:30</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Teardrop</td>\n",
       "      <td>5 minute</td>\n",
       "      <td>Flying corkscrews  Looking to th east at abou...</td>\n",
       "      <td>Source of the report elects to remain anonymous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/4/2017 04:50</td>\n",
       "      <td>Taft, CA</td>\n",
       "      <td>Changing</td>\n",
       "      <td>20 second</td>\n",
       "      <td>I'm a truck driver and I've seen the reddish/...</td>\n",
       "      <td>Witness indicates \"Taft, Indiana\" in origina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Datetime             Location       Shape   Duration  \\\n",
       "0   5/6/2017 05:00     Camp McGregor, NM       Light   10 minute   \n",
       "1   5/5/2017 11:30            Austin, TX        Disk    3 second   \n",
       "2   5/4/2017 21:27           Phoenix, AZ      Circle   15 second   \n",
       "3   5/4/2017 18:30           Phoenix, AZ    Teardrop    5 minute   \n",
       "4   5/4/2017 04:50              Taft, CA    Changing   20 second   \n",
       "\n",
       "                                                Text  \\\n",
       "0   Light seen over mountain's east of Camp McGre...   \n",
       "1   Flying saucer descends, possibly lands in Nor...   \n",
       "2   Orange round sphere.  Orange glowing sphere f...   \n",
       "3   Flying corkscrews  Looking to th east at abou...   \n",
       "4   I'm a truck driver and I've seen the reddish/...   \n",
       "\n",
       "                                               Notes  \n",
       "0    Report appears to us to be consistent with t...  \n",
       "1    We would like to communicate with this witne...  \n",
       "2    We have amended the time above, to reflect a...  \n",
       "3    Source of the report elects to remain anonymous  \n",
       "4    Witness indicates \"Taft, Indiana\" in origina...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ufo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        light seen over mountain east  camp mcgregor ...\n",
       "1        flying saucer descends possibly lands  north ...\n",
       "2        orange round sphere  orange glowing sphere fl...\n",
       "3        flying corkscrews  looking   east  about   sa...\n",
       "4          truck driver and  seen the reddishorange ba...\n",
       "                              ...                        \n",
       "2731     brightly lit craft flew and hovered right  fr...\n",
       "2732     triangle bright flashing white light releasin...\n",
       "2733     light orange red fast speed    and  were look...\n",
       "2734     three circular flashing ufo moving  erratic p...\n",
       "2735     fireball came  from east and made sharp turn ...\n",
       "Name: Text, Length: 2736, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pre = df.iloc[:, 4]\n",
    "text_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(df.iloc[:, 4]):\n",
    "    #df.iloc[:, 5].str.replace('\\d+', '') # for digits\n",
    "    df.iloc[idx, 4] = doc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data for NLP algorithm. Could also use df.apply(lambda x)\n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.replace('\\d+', '') # for digits\n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "#df.iloc[:, 5] = df.iloc[:, 5].str.replace('[^\\w\\s]', '') # for punctuation \n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.replace(r'[^\\w\\s]+', '')\n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.lower()\n",
    "#df.iloc[:, 5] = df.iloc[:, 5].str.replace(string.punctuation, '') # for punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        light seen over mountain east  camp mcgregor ...\n",
       "1        flying saucer descends possibly lands  north ...\n",
       "2        orange round sphere  orange glowing sphere fl...\n",
       "3        flying corkscrews  looking   east  about   sa...\n",
       "4          truck driver and  seen the reddishorange ba...\n",
       "                              ...                        \n",
       "2731     brightly lit craft flew and hovered right  fr...\n",
       "2732     triangle bright flashing white light releasin...\n",
       "2733     light orange red fast speed    and  were look...\n",
       "2734     three circular flashing ufo moving  erratic p...\n",
       "2735     fireball came  from east and made sharp turn ...\n",
       "Name: Text, Length: 2736, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.iloc[:, 4]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [pipelinize source](https://evisionindia.wordpress.com/2020/03/06/setting-up-text-preprocessing-pipeline-using-scikit-learn-and-spacy-learn-how-to-tokenize-lemmatize-remove-stop-words-and-punctuation-with-sklearn-pipelines/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# This both tokenizes and lemmatizes \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "n_features=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maureen/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2736, 3098)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', max_features=n_features,\n",
    "                       ngram_range=(1,2),\n",
    "                       tokenizer=LemmaTokenizer(),\n",
    "                       strip_accents = 'unicode', # works \n",
    "                       lowercase = True, # works\n",
    "                       max_df = 0.5, # works\n",
    "                       min_df = 10 # works\n",
    "                       #, tokenizer=PorterTokenizer()\n",
    "                      )\n",
    "words = vect.fit_transform(text)\n",
    "V = words.toarray()\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling using output of TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.17499044251189"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components)\n",
    "nmf.fit(V)\n",
    "W = nmf.transform(V)\n",
    "H = nmf.components_\n",
    "\n",
    "nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3098)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: like, saw, just, craft, date, looked, sighting, time, approximate, indicates\n",
      "2: provides, information, contact information, provides contact, contact, anonymous provides, witness elect, red, orange, moving\n",
      "3: launch, missile, missile launch, note navy, navy missile, navy, blue, bright, white, cloud\n",
      "4: minute, minute later, minute nuforc, later, sky minute, watched, stationary, minute moved, went, bright\n",
      "5: object, object wa, second, appeared, east, west, flying, moving, video, photo\n"
     ]
    }
   ],
   "source": [
    "index_val = np.argsort(H)[:, -1:-11:-1]\n",
    "\n",
    "for i, lat_feat in enumerate(index_val):\n",
    "    print('%d: %s'%(i+1,', '.join([feature_names[n] for n in lat_feat])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 0.039783s\n",
      "Explained variance of the SVD step: 4%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "t0 = time()\n",
    "# Vectorizer results are normalized, which makes KMeans behave as\n",
    "# spherical k-means for better results. Since LSA/SVD results are\n",
    "# not normalized, we have to redo the normalization.\n",
    "svd = TruncatedSVD(n_components)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "X = lsa.fit_transform(words)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(\n",
    "    int(explained_variance * 100)))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
      "       n_clusters=10, n_init=1, n_jobs=None, precompute_distances='auto',\n",
      "       random_state=None, tol=0.0001, verbose=False)\n",
      "done in 0.018s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=10, init='k-means++', max_iter=100, n_init=1,\n",
    "            verbose=False)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "# print(\"Adjusted Rand-Index: %.3f\"\n",
    "#       % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "#       % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 1: provides information contact contact information object\n",
      "Cluster 2: object minute bright like saw\n",
      "Cluster 3: object like saw just time\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "#     else:\n",
    "#         order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms = vect.get_feature_names()\n",
    "for i in range(1, n_components +1):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
