{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Location</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Text</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/6/2017 05:00</td>\n",
       "      <td>Camp McGregor, NM</td>\n",
       "      <td>Light</td>\n",
       "      <td>10 minute</td>\n",
       "      <td>Light seen over mountain's east of Camp McGre...</td>\n",
       "      <td>Report appears to us to be consistent with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/5/2017 11:30</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Disk</td>\n",
       "      <td>3 second</td>\n",
       "      <td>Flying saucer descends, possibly lands in Nor...</td>\n",
       "      <td>We would like to communicate with this witne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/4/2017 21:27</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Circle</td>\n",
       "      <td>15 second</td>\n",
       "      <td>Orange round sphere.  Orange glowing sphere f...</td>\n",
       "      <td>We have amended the time above, to reflect a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/4/2017 18:30</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>Teardrop</td>\n",
       "      <td>5 minute</td>\n",
       "      <td>Flying corkscrews  Looking to th east at abou...</td>\n",
       "      <td>Source of the report elects to remain anonymous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/4/2017 04:50</td>\n",
       "      <td>Taft, CA</td>\n",
       "      <td>Changing</td>\n",
       "      <td>20 second</td>\n",
       "      <td>I'm a truck driver and I've seen the reddish/...</td>\n",
       "      <td>Witness indicates \"Taft, Indiana\" in origina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Datetime             Location       Shape   Duration  \\\n",
       "0   5/6/2017 05:00     Camp McGregor, NM       Light   10 minute   \n",
       "1   5/5/2017 11:30            Austin, TX        Disk    3 second   \n",
       "2   5/4/2017 21:27           Phoenix, AZ      Circle   15 second   \n",
       "3   5/4/2017 18:30           Phoenix, AZ    Teardrop    5 minute   \n",
       "4   5/4/2017 04:50              Taft, CA    Changing   20 second   \n",
       "\n",
       "                                                Text  \\\n",
       "0   Light seen over mountain's east of Camp McGre...   \n",
       "1   Flying saucer descends, possibly lands in Nor...   \n",
       "2   Orange round sphere.  Orange glowing sphere f...   \n",
       "3   Flying corkscrews  Looking to th east at abou...   \n",
       "4   I'm a truck driver and I've seen the reddish/...   \n",
       "\n",
       "                                               Notes  \n",
       "0    Report appears to us to be consistent with t...  \n",
       "1    We would like to communicate with this witne...  \n",
       "2    We have amended the time above, to reflect a...  \n",
       "3    Source of the report elects to remain anonymous  \n",
       "4    Witness indicates \"Taft, Indiana\" in origina...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ufo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Light seen over mountain's east of Camp McGre...\n",
       "1        Flying saucer descends, possibly lands in Nor...\n",
       "2        Orange round sphere.  Orange glowing sphere f...\n",
       "3        Flying corkscrews  Looking to th east at abou...\n",
       "4        I'm a truck driver and I've seen the reddish/...\n",
       "                              ...                        \n",
       "2731     Brightly lit craft flew and hovered right in ...\n",
       "2732     Triangle bright flashing white light, releasi...\n",
       "2733     Light, orange, red, fast speed.  My gf and I ...\n",
       "2734     Three circular, flashing UFO's moving in erra...\n",
       "2735     Fireball came in from east and made sharp tur...\n",
       "Name: Text, Length: 2736, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pre = df.iloc[:, 4]\n",
    "text_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(df.iloc[:, 4]):\n",
    "    #df.iloc[:, 5].str.replace('\\d+', '') # for digits\n",
    "    df.iloc[idx, 4] = doc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data for NLP algorithm. Could also use df.apply(lambda x)\n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.replace('\\d+', '') # for digits\n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "#df.iloc[:, 5] = df.iloc[:, 5].str.replace('[^\\w\\s]', '') # for punctuation \n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.replace(r'[^\\w\\s]+', '')\n",
    "df.iloc[:, 4] = df.iloc[:, 4].str.lower()\n",
    "#df.iloc[:, 5] = df.iloc[:, 5].str.replace(string.punctuation, '') # for punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        light seen over mountain east  camp mcgregor ...\n",
       "1        flying saucer descends possibly lands  north ...\n",
       "2        orange round sphere  orange glowing sphere fl...\n",
       "3        flying corkscrews  looking   east  about   sa...\n",
       "4          truck driver and  seen the reddishorange ba...\n",
       "                              ...                        \n",
       "2731     brightly lit craft flew and hovered right  fr...\n",
       "2732     triangle bright flashing white light releasin...\n",
       "2733     light orange red fast speed    and  were look...\n",
       "2734     three circular flashing ufo moving  erratic p...\n",
       "2735     fireball came  from east and made sharp turn ...\n",
       "Name: Text, Length: 2736, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.iloc[:, 4]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [pipelinize source](https://evisionindia.wordpress.com/2020/03/06/setting-up-text-preprocessing-pipeline-using-scikit-learn-and-spacy-learn-how-to-tokenize-lemmatize-remove-stop-words-and-punctuation-with-sklearn-pipelines/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This both tokenizes and lemmatizes \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 7\n",
    "n_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maureen/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2736, 1000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', max_features=n_features,\n",
    "                       ngram_range=(1,1),\n",
    "                       tokenizer=LemmaTokenizer(),\n",
    "                       strip_accents = 'unicode', # works \n",
    "                       lowercase = True, # works\n",
    "                       max_df = 0.5, # works\n",
    "                       min_df = 10 # works\n",
    "                       #, tokenizer=PorterTokenizer()\n",
    "                      )\n",
    "words = vect.fit_transform(text)\n",
    "V = words.toarray()\n",
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.003509558298624"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components)\n",
    "nmf.fit(V)\n",
    "W = nmf.transform(V)\n",
    "H = nmf.components_\n",
    "\n",
    "nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: like, saw, just, looked, star, time, sighting, date, went, night\n",
      "2: information, provides, contact, red, green, source, bright, disappeared, hovering, report\n",
      "3: launch, missile, blue, navy, bright, white, cloud, green, trail, beam\n",
      "4: object, appeared, photo, flying, video, shaped, high, approximately, direction, time\n",
      "5: minute, later, hovered, watched, stationary, moved, stayed, went, disappeared, bright\n",
      "6: craft, red, triangle, flying, white, formation, shaped, low, triangular, flashing\n",
      "7: orange, moving, east, west, fireball, north, orb, second, south, disappeared\n"
     ]
    }
   ],
   "source": [
    "index_val = np.argsort(H)[:, -1:-11:-1]\n",
    "\n",
    "for i, lat_feat in enumerate(index_val):\n",
    "    print('%d: %s'%(i+1,', '.join([feature_names[n] for n in lat_feat])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with SVD\n",
    "\n",
    "Vectorizer results are normalized, which makes KMeans behave as spherical k-means for better results. Since LSA/SVD results are not normalized, we have to redo the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "Explained variance of the SVD step: 6%\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "\n",
    "svd = TruncatedSVD(n_components)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "X = lsa.fit_transform(words)\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(\n",
    "    int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
      "       n_clusters=7, n_init=1, n_jobs=None, precompute_distances='auto',\n",
      "       random_state=None, tol=0.0001, verbose=False)\n",
      "done in 0.023s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=n_components, init='k-means++', max_iter=100, n_init=1,\n",
    "            verbose=False)\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "km.fit(X)\n",
    "\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "# print(\"Adjusted Rand-Index: %.3f\"\n",
    "#       % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "#       % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: bright, minute, like, star, saw, green, information, looked, provides, contact\n",
      "2: like, saw, just, looked, time, craft, sighting, date, star, seen\n",
      "3: craft, red, flying, formation, white, triangle, information, provides, shaped, contact\n",
      "4: information, provides, contact, red, bright, green, white, moving, flashing, disappeared\n",
      "5: bright, launch, missile, navy, blue, white, cloud, green, like, trail\n",
      "6: object, moving, appeared, white, flying, time, red, like, saw, bright\n",
      "7: orange, moving, bright, east, west, fireball, provides, information, contact, disappeared\n"
     ]
    }
   ],
   "source": [
    "# Get the centroids and print out the top words for each centroid\n",
    "original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "\n",
    "terms = vect.get_feature_names()\n",
    "for i in range(0, n_components):\n",
    "    print(f'{i+1}: ', end='')\n",
    "    topic_words = [terms[j] for j in order_centroids[i, :10]]\n",
    "    print(', '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bright',\n",
       " 'minute',\n",
       " 'like',\n",
       " 'star',\n",
       " 'saw',\n",
       " 'green',\n",
       " 'information',\n",
       " 'looked',\n",
       " 'provides',\n",
       " 'contact',\n",
       " 'just']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[terms[i] for i in order_centroids[0, :11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
